{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Multiple views of storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = torch.full((13,13), 1)#### Generating a matrix\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1],\n",
       "        [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2],\n",
       "        [1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1],\n",
       "        [1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1],\n",
       "        [1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1],\n",
       "        [1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1],\n",
       "        [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2],\n",
       "        [1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1],\n",
       "        [1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1],\n",
       "        [1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1],\n",
       "        [1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1],\n",
       "        [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2],\n",
       "        [1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = torch.tensor([1,6,11])\n",
    "m1 = m.index_fill_(0,index, 2)\n",
    "m1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1],\n",
       "        [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2],\n",
       "        [1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1],\n",
       "        [1, 2, 1, 3, 3, 1, 2, 1, 3, 3, 1, 2, 1],\n",
       "        [1, 2, 1, 3, 3, 1, 2, 1, 3, 3, 1, 2, 1],\n",
       "        [1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1],\n",
       "        [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2],\n",
       "        [1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1],\n",
       "        [1, 2, 1, 3, 3, 1, 2, 1, 3, 3, 1, 2, 1],\n",
       "        [1, 2, 1, 3, 3, 1, 2, 1, 3, 3, 1, 2, 1],\n",
       "        [1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1],\n",
       "        [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2],\n",
       "        [1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices = (torch.LongTensor([3, 4, 8, 9, 8, 9, 3, 4, 3, 3, 4, 4, 8, 8, 9, 9]),\n",
    "           torch.LongTensor([3, 4, 8, 9, 3, 4, 8, 9, 4, 9, 3, 8, 4, 9, 3, 8]))\n",
    "value = torch.tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3])\n",
    "m2 = m1.index_put_(indices, value)\n",
    "m2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Eigen decomposition "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.eig(\n",
       "eigenvalues=tensor([[20.0000,  0.0000],\n",
       "        [ 1.0000,  0.0000],\n",
       "        [19.0000,  0.0000],\n",
       "        [ 2.0000,  0.0000],\n",
       "        [ 3.0000,  0.0000],\n",
       "        [18.0000,  0.0000],\n",
       "        [ 4.0000,  0.0000],\n",
       "        [ 5.0000,  0.0000],\n",
       "        [17.0000,  0.0000],\n",
       "        [ 6.0000,  0.0000],\n",
       "        [16.0000,  0.0000],\n",
       "        [15.0000,  0.0000],\n",
       "        [14.0000,  0.0000],\n",
       "        [ 7.0000,  0.0000],\n",
       "        [ 8.0000,  0.0000],\n",
       "        [ 9.0000,  0.0000],\n",
       "        [13.0000,  0.0000],\n",
       "        [12.0000,  0.0000],\n",
       "        [10.0000,  0.0000],\n",
       "        [11.0000,  0.0000]]),\n",
       "eigenvectors=tensor([]))"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M = torch.empty((20,20)).normal_() ##Matrix with gaussian coefficients\n",
    "\n",
    "a = torch.arange(1,21,dtype=torch.float)\n",
    "D = torch.diag(a) ##Diagonal matrix\n",
    "\n",
    "M_inv = torch.inverse(M) ## Inverse of matrix M\n",
    "\n",
    "MD = torch.mm(D,M) ## Product of Diagonal matrix and matrix M\n",
    "MM = torch.mm(M_inv,MD) ## Product of inverse matrix and MD\n",
    "\n",
    "eigenvalues = torch.eig(MM,eigenvectors=False)\n",
    "eigenvalues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Flops per second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to generate two matrices is 0.25444496599993727sec\n",
      "Time taken to multiply two matrices is 1.9309690440004488sec\n"
     ]
    }
   ],
   "source": [
    "from time import perf_counter\n",
    "t0 = perf_counter()\n",
    "M1 = torch.empty(5000, 5000).normal_()\n",
    "\n",
    "t1 = perf_counter()\n",
    "M2 = torch.empty(5000, 5000).normal_()\n",
    "\n",
    "t2 = perf_counter()\n",
    "M = torch.mm(M1, M2)\n",
    "tf = perf_counter()\n",
    "print('Time taken to generate two matrices is {}sec'.format(t2-t0))\n",
    "print('Time taken to multiply two matrices is {}sec'.format(tf-t2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Floating point products have been executed per second is 129.46867313940322 Gigaflops.\n"
     ]
    }
   ],
   "source": [
    "Flops_per_sec = 2*(5000**3)/(1e9*(tf-t2)) ##O(2m^3)\n",
    "print('Floating point products have been executed per second is {} Gigaflops.'.format(Flops_per_sec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Playing with slides"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function mulË™row, using python loops (and not even slicing operators), that gets a 2d tensor\n",
    "as argument, and returns a tensor of same size, whose first row is identical to the first row of the\n",
    "argument tensor, the second row is multiplied by two, the third by three, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mul_row(m):\n",
    "    row_num  = m.shape[0]\n",
    "    col_num = m.shape[1]\n",
    "    N = torch.empty((row_num, col_num)) \n",
    "    \n",
    "    t0 = perf_counter()    \n",
    "    for i in range(row_num):\n",
    "\n",
    "        N[i]= (i+1) * m[i]\n",
    "#         print(i)\n",
    "    tf = perf_counter()\n",
    "    print('Time1:', (tf-t0))\n",
    "    return N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time1: 0.01668564500141656\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[   2.,    2.,    2.,  ...,    2.,    2.,    2.],\n",
       "        [   4.,    4.,    4.,  ...,    4.,    4.,    4.],\n",
       "        [   6.,    6.,    6.,  ...,    6.,    6.,    6.],\n",
       "        ...,\n",
       "        [1996., 1996., 1996.,  ..., 1996., 1996., 1996.],\n",
       "        [1998., 1998., 1998.,  ..., 1998., 1998., 1998.],\n",
       "        [2000., 2000., 2000.,  ..., 2000., 2000., 2000.]])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = torch.full((1000, 400), 2.0)\n",
    "mul_row(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mul_row_fast(m):\n",
    "    row_num  = m.shape[0]\n",
    "    col_num = m.shape[1]\n",
    "    \n",
    "    t0 = perf_counter() \n",
    "    vect = torch.arange(1,row_num+1).reshape(row_num,1)\n",
    "    N = m * vect\n",
    "    tf = perf_counter()    \n",
    "    print('Time2:', (tf-t0))    \n",
    "    return N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time2: 0.0008365700014110189\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[   2.,    2.,    2.,  ...,    2.,    2.,    2.],\n",
       "        [   4.,    4.,    4.,  ...,    4.,    4.,    4.],\n",
       "        [   6.,    6.,    6.,  ...,    6.,    6.,    6.],\n",
       "        ...,\n",
       "        [1996., 1996., 1996.,  ..., 1996., 1996., 1996.],\n",
       "        [1998., 1998., 1998.,  ..., 1998., 1998., 1998.],\n",
       "        [2000., 2000., 2000.,  ..., 2000., 2000., 2000.]])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mul_row_fast(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The time ratio between running time while using loop and broadcasting is  19.945306397878667\n"
     ]
    }
   ],
   "source": [
    "print('The time ratio between running time while using loop and broadcasting is ', 0.01668564500141656/0.0008365700014110189)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using loop take more time,approximately 20 times than the time of using broadcasting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
